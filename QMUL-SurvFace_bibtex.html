<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><!-- saved from url=(0055)https://qmul-survface.github.io/QMUL-SurvFace/index.htm --><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <title>QMUL-SurvFace</title><meta name="description" content="To facilitate more studies on developing face recognition models that are effective and robust 					  for low-resolution surveillance facial images, we introduce a new Surveillance Face Recognition Challenge, 					  which we call the QMUL-SurvFace benchmark. 					  This new benchmark is the largest and more importantly the only true surveillance face recognition benchmark 					  to our best knowledge, where low-resolution images are not synthesised by artificial down-sampling 					  of native high-resolution images. This challenge contains 463,507 face images of 15,573 distinct identities 					  captured in real-world uncooperative surveillance scenes over wide space and time. 					  Face recognition is generally more difficult in an open-set setting which is typical for surveillance scenarios, 					  owing to a large number of non-target people (distractors) appearing open spaced scenes."><meta name="keywords" content="face recognition; surveillance face; surveillance face recognition; open-set recognition; closed-set recognition; low-resolution; super-resolution; benchmarks; computer vision;">    </head><body>@article{cheng2018surveillance,<br>  title={Surveillance Face Recognition Challenge},<br>  author={Cheng, Zhiyi and Zhu, Xiatian and Gong, Shaogang},<br>  journal={arXiv preprint arXiv:1804.09691},<br>  year={2018},<br>  url = {https://arxiv.org/pdf/1804.09691.pdf}<br>}</body></html>