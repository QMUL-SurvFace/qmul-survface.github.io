<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0055)https://qmul-survface.github.io/QMUL-SurvFace/index.htm -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
<title>QMUL-SurvFace</title>

<!-- Fonts and stuff -->
<link href="./QMUL-SurvFace_files/css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./QMUL-SurvFace_files/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./QMUL-SurvFace_files/iconize.css">
<script type="text/javascript" async="" src="./QMUL-SurvFace_files/ga.js"></script><script async="" src="./QMUL-SurvFace_files/prettify.js"></script><!-- End Jekyll SEO tag -->

    <script type="text/javascript">
        
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-22940424-1']);
        _gaq.push(['_trackPageview']);
        
        (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
        
    </script>
    
  </head>

<body><div id="pratikabuSTTDiv" class="pratikabusttdiv-no-print" style="bottom: 20px; right: 20px; opacity: 1; display: block;"><img id="pratikabuSTTArrowUp" style="float: right; opacity: 0.5; cursor: pointer; width: 48px; height: 48px; transform: rotate(180deg);" class="pratikabuSTTImg" src="chrome-extension://hegiignepmecppikdlbohnnbfjdoaghj/icons/pratikabu-stt-48-1.png"><div id="pratikabuSTTDiv2" class="pratikabusttdiv-no-print" style="width: 48px; margin-left: 0px;"><img id="pratikabuSTTClear" class="pratikabuSTTImg" src="chrome-extension://hegiignepmecppikdlbohnnbfjdoaghj/icons/pratikabu-stt-clear-24.png" style="opacity: 0.5; cursor: pointer;"><img id="pratikabuSTTPageUp" class="pratikabuSTTImg" src="chrome-extension://hegiignepmecppikdlbohnnbfjdoaghj/icons/pratikabu-stt-pageup-24.png" style="opacity: 0.5; cursor: pointer;"><img id="pratikabuSTTSettings" class="pratikabuSTTImg" src="chrome-extension://hegiignepmecppikdlbohnnbfjdoaghj/icons/pratikabu-stt-settings-24.png" style="opacity: 0.5; cursor: pointer; transform: rotate(0deg);"><img id="pratikabuSTTPageDown" class="pratikabuSTTImg" src="chrome-extension://hegiignepmecppikdlbohnnbfjdoaghj/icons/pratikabu-stt-pageup-24.png" style="opacity: 0.5; cursor: pointer; transform: rotate(180deg);"></div></div>
  <div id="content">
    <div id="content-inner">

    <div class="section head">
	<h1 id="surveillance-face-recognition-challenge">Surveillance Face Recognition Challenge</h1>
	
    <div class="affiliations">
    <p><a href="http://vision.eecs.qmul.ac.uk/">Computer Vision Group, Queen Mary University of London</a>
    

    <p><a href="http://www.eecs.qmul.ac.uk/~zc302/">Zhiyi Cheng</a>    
	    <a href="http://www.eecs.qmul.ac.uk/~xiatian/">Xiatian Zhu</a>   
	    <a href="http://www.eecs.qmul.ac.uk/~sgg/">Shaogang Gong</a>
    </div>
    <ul id="tabs">
    	<li><a href="https://qmul-survface.github.io/QMUL-SurvFace.htm" name="#tab1">Home</a></li>
    	<li><a href="https://qmul-survface.github.io/QMUL-SurvFace.htm" name="#tab2">Results</a></li>  
	</ul> 
    </div>

    <center><img style="width: 920px;" src="./images/web-vs-surv.png" alt="arxiv2018"><center>
    </div>


<ul>
<h2 id="news">News</h2>
<p>
Dataset, test protocol and test code: <strong>Coming Soon</strong>
</ul>
<p></p>


<ul>
<h2 id="description">Description</h2>
<p>To facilitate more studies on developing FR models that are effective and robust for low-resolution surveillance facial images, we introduce a new Surveillance Face Recognition Challenge, which we call the QMUL-SurvFace benchmark. This new benchmark is the largest and more importantly the only true surveillance FR benchmark to our best knowledge, where low-resolution images are not synthesised by artificial down-sampling of native high-resolution images. This challenge contains 463,507 face images of 15,573 distinct identities captured in real-world uncooperative surveillance scenes over wide space and time. 
Face recognition is generally more difficult in an
open-set setting which is typical for surveillance scenarios,
owing to a large number of non-target people
(distractors) appearing open spaced scenes.
<p></p>


<h2 id="download">Download</h2>
<p>QMUL-SurvFace Training Images <strong>Coming Soon</strong>
<p></p>


<h2 id="benchmark">Benchmark</h2>
<p>For details on the evaluation scheme please refer to the <a href="https://arxiv.org/pdf/1804.09691.pdf">technical report</a>.</p>
<h3 id="identification">Identification</h3>
<p>Performance curves
(Protocol: Open-Set. Metrics: TPIR20@FPIR (r = 20).)</p>


<p><img style="width: 260px;" src="./images/all_fr_curves.png" alt="arxiv2018"></p>

<h3 id="verification">Verification</h3>
<p>Metric: Mean Accuracy.</p>

<p><img style="width: 300px;" src="./images/verification_result.png" alt="arxiv2018"></p>

<div class="section bibtex">
<h2 id="citation">Citation</h2>
<pre>
@article{cheng2018surveillance,
  title={Surveillance Face Recognition Challenge},
  author={Cheng, Zhiyi and Zhu, Xiatian and Gong, Shaogang},
  journal={arXiv preprint arXiv:1804.09691},
  year={2018}
}
	</pre>
	</div>

<h2 id="contact">Contact</h2>
<p>For questions, please contact Zhiyi Cheng at z.cheng@qmul.ac.uk</p>


    
<br>
<br>


</div></body></html>
